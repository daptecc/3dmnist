{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dataset import MNIST3dDataset, get_dataloaders\n",
    "from model import MNIST3dModel\n",
    "from run import main\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MNIST3dModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 8, 16, 16, 16]             656\n",
      "            Conv3d-2       [-1, 16, 16, 16, 16]           3,472\n",
      "              ReLU-3       [-1, 16, 16, 16, 16]               0\n",
      "       BatchNorm3d-4       [-1, 16, 16, 16, 16]              32\n",
      "         MaxPool3d-5          [-1, 16, 8, 8, 8]               0\n",
      "            Conv3d-6          [-1, 32, 8, 8, 8]          13,856\n",
      "            Conv3d-7          [-1, 64, 8, 8, 8]          55,360\n",
      "              ReLU-8          [-1, 64, 8, 8, 8]               0\n",
      "       BatchNorm3d-9          [-1, 64, 8, 8, 8]             128\n",
      "        MaxPool3d-10          [-1, 64, 4, 4, 4]               0\n",
      "          Dropout-11          [-1, 64, 4, 4, 4]               0\n",
      "           Linear-12                 [-1, 1024]       4,195,328\n",
      "             ReLU-13                 [-1, 1024]               0\n",
      "          Dropout-14                 [-1, 1024]               0\n",
      "           Linear-15                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 4,279,082\n",
      "Trainable params: 4,279,082\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.77\n",
      "Params size (MB): 16.32\n",
      "Estimated Total Size (MB): 19.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 16, 16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 80, 'eval_every_n_epochs': 1, 'fine_tune_from': 'None', 'log_every_n_steps': 200, 'fp16_precision': False, 'dataset': {'path': 'data/full_dataset_vectors.h5', 'num_classes': 10, 'num_workers': 4}}\n",
      "Running on: cuda\n",
      "Pre-trained weights not found. Training from scratch.\n",
      "[1/80] loss: 2.48, acc 0.12\n",
      "[1/80] val_loss: 7.69, val_acc 0.15\n",
      "[2/80] loss: 1.89, acc 0.37\n",
      "[2/80] val_loss: 2.38, val_acc 0.48\n",
      "[3/80] val_loss: 3.60, val_acc 0.47\n",
      "[4/80] loss: 1.54, acc 0.48\n",
      "[4/80] val_loss: 39.43, val_acc 0.10\n",
      "[5/80] loss: 1.39, acc 0.53\n",
      "[5/80] val_loss: 1.62, val_acc 0.57\n",
      "[6/80] val_loss: 0.92, val_acc 0.68\n",
      "[7/80] loss: 1.29, acc 0.56\n",
      "[7/80] val_loss: 0.91, val_acc 0.69\n",
      "[8/80] loss: 1.21, acc 0.58\n",
      "[8/80] val_loss: 1.36, val_acc 0.55\n",
      "[9/80] val_loss: 0.97, val_acc 0.67\n",
      "[10/80] loss: 1.15, acc 0.61\n",
      "[10/80] val_loss: 1.16, val_acc 0.60\n",
      "[11/80] loss: 1.09, acc 0.62\n",
      "[11/80] val_loss: 8.97, val_acc 0.23\n",
      "[12/80] val_loss: 0.88, val_acc 0.73\n",
      "[13/80] loss: 1.04, acc 0.64\n",
      "[13/80] val_loss: 0.76, val_acc 0.74\n",
      "[14/80] loss: 0.98, acc 0.66\n",
      "[14/80] val_loss: 0.98, val_acc 0.72\n",
      "[15/80] val_loss: 2.08, val_acc 0.63\n",
      "[16/80] loss: 0.93, acc 0.68\n",
      "[16/80] val_loss: 0.91, val_acc 0.74\n",
      "[17/80] loss: 0.88, acc 0.70\n",
      "[17/80] val_loss: 0.90, val_acc 0.75\n",
      "[18/80] val_loss: 1.67, val_acc 0.66\n",
      "[19/80] loss: 0.84, acc 0.71\n",
      "[19/80] val_loss: 0.86, val_acc 0.76\n",
      "[20/80] loss: 0.79, acc 0.73\n",
      "[20/80] val_loss: 1.06, val_acc 0.72\n",
      "[21/80] val_loss: 0.85, val_acc 0.77\n",
      "[22/80] loss: 0.75, acc 0.74\n",
      "[22/80] val_loss: 0.85, val_acc 0.77\n",
      "[23/80] loss: 0.72, acc 0.75\n",
      "[23/80] val_loss: 1.01, val_acc 0.76\n",
      "[24/80] val_loss: 0.98, val_acc 0.76\n",
      "[25/80] loss: 0.68, acc 0.77\n",
      "[25/80] val_loss: 0.82, val_acc 0.78\n",
      "[26/80] loss: 0.65, acc 0.78\n",
      "[26/80] val_loss: 0.89, val_acc 0.77\n",
      "[27/80] val_loss: 0.84, val_acc 0.78\n",
      "[28/80] loss: 0.62, acc 0.79\n",
      "[28/80] val_loss: 0.84, val_acc 0.78\n",
      "[29/80] loss: 0.60, acc 0.80\n",
      "[29/80] val_loss: 0.88, val_acc 0.78\n",
      "[30/80] val_loss: 0.86, val_acc 0.77\n",
      "[31/80] loss: 0.57, acc 0.80\n",
      "[31/80] val_loss: 0.86, val_acc 0.78\n",
      "[32/80] loss: 0.55, acc 0.81\n",
      "[32/80] val_loss: 0.88, val_acc 0.77\n",
      "[33/80] val_loss: 0.86, val_acc 0.78\n",
      "[34/80] loss: 0.53, acc 0.82\n",
      "[34/80] val_loss: 0.86, val_acc 0.78\n",
      "[35/80] loss: 0.51, acc 0.82\n",
      "[35/80] val_loss: 0.85, val_acc 0.78\n",
      "[36/80] val_loss: 0.85, val_acc 0.78\n",
      "[37/80] loss: 0.49, acc 0.83\n",
      "[37/80] val_loss: 0.85, val_acc 0.78\n",
      "[38/80] loss: 0.48, acc 0.84\n",
      "[38/80] val_loss: 0.85, val_acc 0.78\n",
      "[39/80] val_loss: 0.85, val_acc 0.78\n",
      "[40/80] loss: 0.46, acc 0.84\n",
      "[40/80] val_loss: 0.85, val_acc 0.78\n",
      "[41/80] loss: 0.45, acc 0.85\n",
      "[41/80] val_loss: 0.86, val_acc 0.78\n",
      "[42/80] val_loss: 0.86, val_acc 0.78\n",
      "[43/80] loss: 0.44, acc 0.85\n",
      "[43/80] val_loss: 0.86, val_acc 0.78\n",
      "[44/80] loss: 0.43, acc 0.85\n",
      "[44/80] val_loss: 0.85, val_acc 0.78\n",
      "[45/80] val_loss: 0.85, val_acc 0.78\n",
      "[46/80] loss: 0.42, acc 0.86\n",
      "[46/80] val_loss: 0.85, val_acc 0.78\n",
      "[47/80] loss: 0.40, acc 0.86\n",
      "[47/80] val_loss: 0.86, val_acc 0.78\n",
      "[48/80] val_loss: 0.85, val_acc 0.78\n",
      "[49/80] loss: 0.40, acc 0.87\n",
      "[49/80] val_loss: 0.86, val_acc 0.78\n",
      "[50/80] loss: 0.39, acc 0.87\n",
      "[50/80] val_loss: 0.86, val_acc 0.78\n",
      "[51/80] val_loss: 0.86, val_acc 0.78\n",
      "[52/80] loss: 0.38, acc 0.87\n",
      "[52/80] val_loss: 0.86, val_acc 0.78\n",
      "[53/80] loss: 0.37, acc 0.87\n",
      "[53/80] val_loss: 0.86, val_acc 0.78\n",
      "[54/80] val_loss: 0.86, val_acc 0.78\n",
      "[55/80] loss: 0.36, acc 0.88\n",
      "[55/80] val_loss: 0.86, val_acc 0.78\n",
      "[56/80] loss: 0.35, acc 0.88\n",
      "[56/80] val_loss: 0.86, val_acc 0.78\n",
      "[57/80] val_loss: 0.86, val_acc 0.78\n",
      "[58/80] loss: 0.35, acc 0.88\n",
      "[58/80] val_loss: 0.86, val_acc 0.78\n",
      "[59/80] loss: 0.34, acc 0.88\n",
      "[59/80] val_loss: 0.86, val_acc 0.78\n",
      "[60/80] val_loss: 0.86, val_acc 0.78\n",
      "[61/80] loss: 0.34, acc 0.89\n",
      "[61/80] val_loss: 0.86, val_acc 0.78\n",
      "[62/80] loss: 0.33, acc 0.89\n",
      "[62/80] val_loss: 0.86, val_acc 0.78\n",
      "[63/80] val_loss: 0.86, val_acc 0.78\n",
      "[64/80] loss: 0.32, acc 0.89\n",
      "[64/80] val_loss: 0.86, val_acc 0.78\n",
      "[65/80] loss: 0.32, acc 0.89\n",
      "[65/80] val_loss: 0.86, val_acc 0.78\n",
      "[66/80] val_loss: 0.86, val_acc 0.78\n",
      "[67/80] loss: 0.31, acc 0.89\n",
      "[67/80] val_loss: 0.86, val_acc 0.78\n",
      "[68/80] loss: 0.31, acc 0.90\n",
      "[68/80] val_loss: 0.86, val_acc 0.78\n",
      "[69/80] val_loss: 0.86, val_acc 0.78\n",
      "[70/80] loss: 0.30, acc 0.90\n",
      "[70/80] val_loss: 0.86, val_acc 0.78\n",
      "[71/80] loss: 0.30, acc 0.90\n",
      "[71/80] val_loss: 0.86, val_acc 0.78\n",
      "[72/80] val_loss: 0.86, val_acc 0.78\n",
      "[73/80] loss: 0.30, acc 0.90\n",
      "[73/80] val_loss: 0.86, val_acc 0.78\n",
      "[74/80] loss: 0.29, acc 0.90\n",
      "[74/80] val_loss: 0.86, val_acc 0.78\n",
      "[75/80] val_loss: 0.86, val_acc 0.78\n",
      "[76/80] loss: 0.29, acc 0.90\n",
      "[76/80] val_loss: 0.86, val_acc 0.78\n",
      "[77/80] loss: 0.28, acc 0.90\n",
      "[77/80] val_loss: 0.86, val_acc 0.78\n",
      "[78/80] val_loss: 0.86, val_acc 0.78\n",
      "[79/80] loss: 0.28, acc 0.91\n",
      "[79/80] val_loss: 0.86, val_acc 0.78\n",
      "[80/80] loss: 0.28, acc 0.91\n",
      "[80/80] val_loss: 0.86, val_acc 0.78\n",
      "\n",
      "\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
