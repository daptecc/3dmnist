{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dataset import MNIST3dDataset, get_dataloaders\n",
    "from model import MNIST3dModel\n",
    "from run import main\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MNIST3dModel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv3d-1        [-1, 8, 16, 16, 16]             656\n            Conv3d-2       [-1, 16, 16, 16, 16]           3,472\n              ReLU-3       [-1, 16, 16, 16, 16]               0\n       BatchNorm3d-4       [-1, 16, 16, 16, 16]              32\n         MaxPool3d-5          [-1, 16, 8, 8, 8]               0\n            Conv3d-6          [-1, 32, 8, 8, 8]          13,856\n            Conv3d-7          [-1, 64, 8, 8, 8]          55,360\n              ReLU-8          [-1, 64, 8, 8, 8]               0\n       BatchNorm3d-9          [-1, 64, 8, 8, 8]             128\n        MaxPool3d-10          [-1, 64, 4, 4, 4]               0\n          Dropout-11          [-1, 64, 4, 4, 4]               0\n           Linear-12                 [-1, 1024]       4,195,328\n             ReLU-13                 [-1, 1024]               0\n          Dropout-14                 [-1, 1024]               0\n           Linear-15                   [-1, 10]          10,250\n================================================================\nTotal params: 4,279,082\nTrainable params: 4,279,082\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.05\nForward/backward pass size (MB): 2.77\nParams size (MB): 16.32\nEstimated Total Size (MB): 19.14\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 16, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 64, 'epochs': 80, 'eval_every_n_epochs': 1, 'fine_tune_from': 'None', 'log_every_n_steps': 200, 'fp16_precision': False, 'dataset': {'path': 'data/full_dataset_vectors.h5', 'num_classes': 10, 'num_workers': 4}}\n",
      "Running on: cuda\n",
      "Pre-trained weights not found. Training from scratch.\n",
      "[1/80] loss: 2.65, acc 0.11\n",
      "[1/80] val_loss: 2.30, val_acc 0.10\n",
      "[2/80] loss: 2.44, acc 0.11\n",
      "[2/80] val_loss: 2.30, val_acc 0.10\n",
      "[3/80] val_loss: 2.30, val_acc 0.10\n",
      "[4/80] loss: 2.37, acc 0.11\n",
      "[4/80] val_loss: 2.30, val_acc 0.10\n",
      "[5/80] loss: 2.35, acc 0.11\n",
      "[5/80] val_loss: 2.32, val_acc 0.10\n",
      "[6/80] val_loss: 2.50, val_acc 0.23\n",
      "[7/80] loss: 2.30, acc 0.13\n",
      "[7/80] val_loss: 2.53, val_acc 0.23\n",
      "[8/80] loss: 2.14, acc 0.20\n",
      "[8/80] val_loss: 8.76, val_acc 0.19\n",
      "[9/80] val_loss: 1.04, val_acc 0.64\n",
      "[10/80] loss: 1.98, acc 0.27\n",
      "[10/80] val_loss: 2.43, val_acc 0.48\n",
      "[11/80] loss: 1.85, acc 0.32\n",
      "[11/80] val_loss: 1.70, val_acc 0.55\n",
      "[12/80] val_loss: 0.99, val_acc 0.66\n",
      "[13/80] loss: 1.74, acc 0.36\n",
      "[13/80] val_loss: 2.75, val_acc 0.46\n",
      "[14/80] loss: 1.64, acc 0.40\n",
      "[14/80] val_loss: 0.92, val_acc 0.67\n",
      "[15/80] val_loss: 2.25, val_acc 0.52\n",
      "[16/80] loss: 1.56, acc 0.43\n",
      "[16/80] val_loss: 0.97, val_acc 0.68\n",
      "[17/80] loss: 1.49, acc 0.46\n",
      "[17/80] val_loss: 0.85, val_acc 0.71\n",
      "[18/80] val_loss: 1.13, val_acc 0.67\n",
      "[19/80] loss: 1.42, acc 0.48\n",
      "[19/80] val_loss: 2.63, val_acc 0.52\n",
      "[20/80] loss: 1.36, acc 0.51\n",
      "[20/80] val_loss: 0.85, val_acc 0.71\n",
      "[21/80] val_loss: 0.89, val_acc 0.71\n",
      "[22/80] loss: 1.31, acc 0.53\n",
      "[22/80] val_loss: 1.12, val_acc 0.69\n",
      "[23/80] loss: 1.26, acc 0.55\n",
      "[23/80] val_loss: 0.87, val_acc 0.72\n",
      "[24/80] val_loss: 0.83, val_acc 0.73\n",
      "[25/80] loss: 1.21, acc 0.56\n",
      "[25/80] val_loss: 1.43, val_acc 0.64\n",
      "[26/80] loss: 1.16, acc 0.58\n",
      "[26/80] val_loss: 0.88, val_acc 0.74\n",
      "[27/80] val_loss: 2.34, val_acc 0.56\n",
      "[28/80] loss: 1.12, acc 0.60\n",
      "[28/80] val_loss: 4.11, val_acc 0.47\n",
      "[29/80] loss: 1.07, acc 0.61\n",
      "[29/80] val_loss: 1.23, val_acc 0.71\n",
      "[30/80] val_loss: 1.30, val_acc 0.71\n",
      "[31/80] loss: 1.03, acc 0.63\n",
      "[31/80] val_loss: 1.87, val_acc 0.66\n",
      "[32/80] loss: 0.99, acc 0.64\n",
      "[32/80] val_loss: 1.11, val_acc 0.73\n",
      "[33/80] val_loss: 0.98, val_acc 0.75\n",
      "[34/80] loss: 0.96, acc 0.66\n",
      "[34/80] val_loss: 0.99, val_acc 0.75\n",
      "[35/80] loss: 0.92, acc 0.67\n",
      "[35/80] val_loss: 1.02, val_acc 0.75\n",
      "[36/80] val_loss: 0.94, val_acc 0.76\n",
      "[37/80] loss: 0.89, acc 0.68\n",
      "[37/80] val_loss: 0.92, val_acc 0.76\n",
      "[38/80] loss: 0.86, acc 0.69\n",
      "[38/80] val_loss: 0.92, val_acc 0.75\n",
      "[39/80] val_loss: 0.91, val_acc 0.76\n",
      "[40/80] loss: 0.83, acc 0.70\n",
      "[40/80] val_loss: 0.91, val_acc 0.76\n",
      "[41/80] loss: 0.80, acc 0.71\n",
      "[41/80] val_loss: 0.90, val_acc 0.76\n",
      "[42/80] val_loss: 0.90, val_acc 0.76\n",
      "[43/80] loss: 0.78, acc 0.72\n",
      "[43/80] val_loss: 0.91, val_acc 0.76\n",
      "[44/80] loss: 0.76, acc 0.73\n",
      "[44/80] val_loss: 0.91, val_acc 0.77\n",
      "[45/80] val_loss: 0.90, val_acc 0.77\n",
      "[46/80] loss: 0.73, acc 0.74\n",
      "[46/80] val_loss: 0.91, val_acc 0.77\n",
      "[47/80] loss: 0.71, acc 0.74\n",
      "[47/80] val_loss: 0.91, val_acc 0.77\n",
      "[48/80] val_loss: 0.91, val_acc 0.77\n",
      "[49/80] loss: 0.69, acc 0.75\n",
      "[49/80] val_loss: 0.91, val_acc 0.77\n",
      "[50/80] loss: 0.68, acc 0.76\n",
      "[50/80] val_loss: 0.91, val_acc 0.77\n",
      "[51/80] val_loss: 0.91, val_acc 0.77\n",
      "[52/80] loss: 0.66, acc 0.76\n",
      "[52/80] val_loss: 0.92, val_acc 0.77\n",
      "[53/80] loss: 0.64, acc 0.77\n",
      "[53/80] val_loss: 0.91, val_acc 0.77\n",
      "[54/80] val_loss: 0.91, val_acc 0.77\n",
      "[55/80] loss: 0.63, acc 0.78\n",
      "[55/80] val_loss: 0.91, val_acc 0.76\n",
      "[56/80] loss: 0.61, acc 0.78\n",
      "[56/80] val_loss: 0.92, val_acc 0.77\n",
      "[57/80] val_loss: 0.92, val_acc 0.77\n",
      "[58/80] loss: 0.60, acc 0.79\n",
      "[58/80] val_loss: 0.92, val_acc 0.77\n",
      "[59/80] loss: 0.59, acc 0.79\n",
      "[59/80] val_loss: 0.91, val_acc 0.76\n",
      "[60/80] val_loss: 0.92, val_acc 0.77\n",
      "[61/80] loss: 0.57, acc 0.79\n",
      "[61/80] val_loss: 0.92, val_acc 0.77\n",
      "[62/80] loss: 0.56, acc 0.80\n",
      "[62/80] val_loss: 0.92, val_acc 0.77\n",
      "[63/80] val_loss: 0.92, val_acc 0.77\n",
      "[64/80] loss: 0.55, acc 0.80\n",
      "[64/80] val_loss: 0.92, val_acc 0.77\n",
      "[65/80] loss: 0.54, acc 0.81\n",
      "[65/80] val_loss: 0.92, val_acc 0.77\n",
      "[66/80] val_loss: 0.92, val_acc 0.77\n",
      "[67/80] loss: 0.53, acc 0.81\n",
      "[67/80] val_loss: 0.92, val_acc 0.77\n",
      "[68/80] loss: 0.52, acc 0.81\n",
      "[68/80] val_loss: 0.92, val_acc 0.77\n",
      "[69/80] val_loss: 0.92, val_acc 0.77\n",
      "[70/80] loss: 0.51, acc 0.82\n",
      "[70/80] val_loss: 0.92, val_acc 0.77\n",
      "[71/80] loss: 0.50, acc 0.82\n",
      "[71/80] val_loss: 0.92, val_acc 0.77\n",
      "[72/80] val_loss: 0.92, val_acc 0.77\n",
      "[73/80] loss: 0.49, acc 0.82\n",
      "[73/80] val_loss: 0.92, val_acc 0.77\n",
      "[74/80] loss: 0.48, acc 0.83\n",
      "[74/80] val_loss: 0.92, val_acc 0.77\n",
      "[75/80] val_loss: 0.92, val_acc 0.77\n",
      "[76/80] loss: 0.48, acc 0.83\n",
      "[76/80] val_loss: 0.92, val_acc 0.77\n",
      "[77/80] loss: 0.47, acc 0.83\n",
      "[77/80] val_loss: 0.92, val_acc 0.77\n",
      "[78/80] val_loss: 0.92, val_acc 0.77\n",
      "[79/80] loss: 0.46, acc 0.84\n",
      "[79/80] val_loss: 0.92, val_acc 0.77\n",
      "[80/80] loss: 0.45, acc 0.84\n",
      "[80/80] val_loss: 0.92, val_acc 0.77\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}